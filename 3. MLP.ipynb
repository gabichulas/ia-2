{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f88a396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/winequality-red.csv\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0042e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.view(data.size(0), -1))  # Flatten para MLP\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Funci√≥n para evaluar el modelo\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.view(data.size(0), -1))  # Flatten para MLP\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return test_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "# Configurar dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d099a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1599, 12)\n",
      "Columnas: ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
      "Tipos: fixed acidity           float64\n",
      "volatile acidity        float64\n",
      "citric acid             float64\n",
      "residual sugar          float64\n",
      "chlorides               float64\n",
      "free sulfur dioxide     float64\n",
      "total sulfur dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                 float64\n",
      "quality                   int64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columnas: {df.columns.tolist()}\")\n",
    "print(f\"Tipos: {df.dtypes}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640e756f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['quality'].value_counts().sort_index()\n",
    "df['quality'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e351b653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality                 1.000000\n",
       "alcohol                 0.476166\n",
       "sulphates               0.251397\n",
       "citric acid             0.226373\n",
       "fixed acidity           0.124052\n",
       "residual sugar          0.013732\n",
       "free sulfur dioxide    -0.050656\n",
       "pH                     -0.057731\n",
       "chlorides              -0.128907\n",
       "density                -0.174919\n",
       "total sulfur dioxide   -0.185100\n",
       "volatile acidity       -0.390558\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "df.corr()['quality'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9607752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('quality', axis=1).values\n",
    "y = df['quality'].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler() \n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=43, stratify=y)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "\n",
    "# Ajustar clases: 3-8 ‚Üí 0-5\n",
    "y_train_tensor = torch.LongTensor(y_train - 3)  \n",
    "y_test_tensor = torch.LongTensor(y_test - 3)\n",
    "\n",
    "# Recrear datasets con las nuevas etiquetas\n",
    "train_dataset = data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, n_classes)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # M√°s conservador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb44ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• √âpoca  1/50 | üìà Train:  36.51% (loss: 1.7197) | üéØ Test:  50.62% (loss: 1.6386)\n",
      "üî• √âpoca  2/50 | üìà Train:  52.23% (loss: 1.5682) | üéØ Test:  55.00% (loss: 1.5004)\n",
      "üî• √âpoca  3/50 | üìà Train:  54.34% (loss: 1.4371) | üéØ Test:  55.31% (loss: 1.3861)\n",
      "üî• √âpoca  4/50 | üìà Train:  54.26% (loss: 1.3332) | üéØ Test:  56.88% (loss: 1.3011)\n",
      "üî• √âpoca  5/50 | üìà Train:  55.28% (loss: 1.2584) | üéØ Test:  56.56% (loss: 1.2419)\n",
      "üî• √âpoca  6/50 | üìà Train:  55.12% (loss: 1.2060) | üéØ Test:  56.88% (loss: 1.1995)\n",
      "üî• √âpoca  7/50 | üìà Train:  55.43% (loss: 1.1681) | üéØ Test:  58.44% (loss: 1.1667)\n",
      "üî• √âpoca  8/50 | üìà Train:  56.22% (loss: 1.1394) | üéØ Test:  59.06% (loss: 1.1404)\n",
      "üî• √âpoca  9/50 | üìà Train:  56.37% (loss: 1.1155) | üéØ Test:  59.38% (loss: 1.1181)\n",
      "üî• √âpoca 10/50 | üìà Train:  58.01% (loss: 1.0959) | üéØ Test:  58.75% (loss: 1.0998)\n",
      "üî• √âpoca 11/50 | üìà Train:  57.39% (loss: 1.0799) | üéØ Test:  59.38% (loss: 1.0837)\n",
      "üî• √âpoca 12/50 | üìà Train:  57.78% (loss: 1.0662) | üéØ Test:  59.38% (loss: 1.0707)\n",
      "üî• √âpoca 13/50 | üìà Train:  58.09% (loss: 1.0547) | üéØ Test:  60.00% (loss: 1.0588)\n",
      "üî• √âpoca 14/50 | üìà Train:  58.01% (loss: 1.0448) | üéØ Test:  59.06% (loss: 1.0497)\n",
      "üî• √âpoca 15/50 | üìà Train:  58.01% (loss: 1.0366) | üéØ Test:  59.69% (loss: 1.0416)\n",
      "üî• √âpoca 16/50 | üìà Train:  58.09% (loss: 1.0293) | üéØ Test:  60.00% (loss: 1.0351)\n",
      "üî• √âpoca 17/50 | üìà Train:  58.33% (loss: 1.0231) | üéØ Test:  60.00% (loss: 1.0292)\n",
      "üî• √âpoca 18/50 | üìà Train:  59.03% (loss: 1.0176) | üéØ Test:  60.00% (loss: 1.0244)\n",
      "üî• √âpoca 19/50 | üìà Train:  59.42% (loss: 1.0126) | üéØ Test:  61.88% (loss: 1.0196)\n",
      "üî• √âpoca 20/50 | üìà Train:  59.81% (loss: 1.0080) | üéØ Test:  62.19% (loss: 1.0157)\n",
      "üî• √âpoca 11/50 | üìà Train:  57.39% (loss: 1.0799) | üéØ Test:  59.38% (loss: 1.0837)\n",
      "üî• √âpoca 12/50 | üìà Train:  57.78% (loss: 1.0662) | üéØ Test:  59.38% (loss: 1.0707)\n",
      "üî• √âpoca 13/50 | üìà Train:  58.09% (loss: 1.0547) | üéØ Test:  60.00% (loss: 1.0588)\n",
      "üî• √âpoca 14/50 | üìà Train:  58.01% (loss: 1.0448) | üéØ Test:  59.06% (loss: 1.0497)\n",
      "üî• √âpoca 15/50 | üìà Train:  58.01% (loss: 1.0366) | üéØ Test:  59.69% (loss: 1.0416)\n",
      "üî• √âpoca 16/50 | üìà Train:  58.09% (loss: 1.0293) | üéØ Test:  60.00% (loss: 1.0351)\n",
      "üî• √âpoca 17/50 | üìà Train:  58.33% (loss: 1.0231) | üéØ Test:  60.00% (loss: 1.0292)\n",
      "üî• √âpoca 18/50 | üìà Train:  59.03% (loss: 1.0176) | üéØ Test:  60.00% (loss: 1.0244)\n",
      "üî• √âpoca 19/50 | üìà Train:  59.42% (loss: 1.0126) | üéØ Test:  61.88% (loss: 1.0196)\n",
      "üî• √âpoca 20/50 | üìà Train:  59.81% (loss: 1.0080) | üéØ Test:  62.19% (loss: 1.0157)\n",
      "üî• √âpoca 21/50 | üìà Train:  59.89% (loss: 1.0041) | üéØ Test:  62.50% (loss: 1.0126)\n",
      "üî• √âpoca 22/50 | üìà Train:  59.81% (loss: 1.0001) | üéØ Test:  63.12% (loss: 1.0093)\n",
      "üî• √âpoca 23/50 | üìà Train:  60.13% (loss: 0.9970) | üéØ Test:  61.88% (loss: 1.0068)\n",
      "üî• √âpoca 24/50 | üìà Train:  60.36% (loss: 0.9939) | üéØ Test:  62.50% (loss: 1.0042)\n",
      "üî• √âpoca 25/50 | üìà Train:  60.20% (loss: 0.9908) | üéØ Test:  62.81% (loss: 1.0022)\n",
      "üî• √âpoca 26/50 | üìà Train:  60.44% (loss: 0.9881) | üéØ Test:  62.81% (loss: 1.0006)\n",
      "üî• √âpoca 27/50 | üìà Train:  60.28% (loss: 0.9856) | üéØ Test:  62.19% (loss: 0.9982)\n",
      "üî• √âpoca 28/50 | üìà Train:  60.52% (loss: 0.9830) | üéØ Test:  61.56% (loss: 0.9968)\n",
      "üî• √âpoca 29/50 | üìà Train:  60.36% (loss: 0.9810) | üéØ Test:  62.81% (loss: 0.9946)\n",
      "üî• √âpoca 30/50 | üìà Train:  60.36% (loss: 0.9789) | üéØ Test:  62.81% (loss: 0.9935)\n",
      "üî• √âpoca 21/50 | üìà Train:  59.89% (loss: 1.0041) | üéØ Test:  62.50% (loss: 1.0126)\n",
      "üî• √âpoca 22/50 | üìà Train:  59.81% (loss: 1.0001) | üéØ Test:  63.12% (loss: 1.0093)\n",
      "üî• √âpoca 23/50 | üìà Train:  60.13% (loss: 0.9970) | üéØ Test:  61.88% (loss: 1.0068)\n",
      "üî• √âpoca 24/50 | üìà Train:  60.36% (loss: 0.9939) | üéØ Test:  62.50% (loss: 1.0042)\n",
      "üî• √âpoca 25/50 | üìà Train:  60.20% (loss: 0.9908) | üéØ Test:  62.81% (loss: 1.0022)\n",
      "üî• √âpoca 26/50 | üìà Train:  60.44% (loss: 0.9881) | üéØ Test:  62.81% (loss: 1.0006)\n",
      "üî• √âpoca 27/50 | üìà Train:  60.28% (loss: 0.9856) | üéØ Test:  62.19% (loss: 0.9982)\n",
      "üî• √âpoca 28/50 | üìà Train:  60.52% (loss: 0.9830) | üéØ Test:  61.56% (loss: 0.9968)\n",
      "üî• √âpoca 29/50 | üìà Train:  60.36% (loss: 0.9810) | üéØ Test:  62.81% (loss: 0.9946)\n",
      "üî• √âpoca 30/50 | üìà Train:  60.36% (loss: 0.9789) | üéØ Test:  62.81% (loss: 0.9935)\n",
      "üî• √âpoca 31/50 | üìà Train:  60.36% (loss: 0.9762) | üéØ Test:  62.19% (loss: 0.9928)\n",
      "üî• √âpoca 32/50 | üìà Train:  59.97% (loss: 0.9744) | üéØ Test:  62.81% (loss: 0.9902)\n",
      "üî• √âpoca 33/50 | üìà Train:  60.13% (loss: 0.9726) | üéØ Test:  62.50% (loss: 0.9886)\n",
      "üî• √âpoca 34/50 | üìà Train:  60.99% (loss: 0.9701) | üéØ Test:  62.19% (loss: 0.9885)\n",
      "üî• √âpoca 35/50 | üìà Train:  60.44% (loss: 0.9684) | üéØ Test:  61.88% (loss: 0.9864)\n",
      "üî• √âpoca 36/50 | üìà Train:  60.83% (loss: 0.9672) | üéØ Test:  62.19% (loss: 0.9861)\n",
      "üî• √âpoca 37/50 | üìà Train:  60.67% (loss: 0.9650) | üéØ Test:  61.88% (loss: 0.9844)\n",
      "üî• √âpoca 38/50 | üìà Train:  60.75% (loss: 0.9635) | üéØ Test:  61.56% (loss: 0.9833)\n",
      "üî• √âpoca 39/50 | üìà Train:  60.59% (loss: 0.9618) | üéØ Test:  61.88% (loss: 0.9818)\n",
      "üî• √âpoca 40/50 | üìà Train:  60.91% (loss: 0.9600) | üéØ Test:  61.25% (loss: 0.9814)\n",
      "üî• √âpoca 31/50 | üìà Train:  60.36% (loss: 0.9762) | üéØ Test:  62.19% (loss: 0.9928)\n",
      "üî• √âpoca 32/50 | üìà Train:  59.97% (loss: 0.9744) | üéØ Test:  62.81% (loss: 0.9902)\n",
      "üî• √âpoca 33/50 | üìà Train:  60.13% (loss: 0.9726) | üéØ Test:  62.50% (loss: 0.9886)\n",
      "üî• √âpoca 34/50 | üìà Train:  60.99% (loss: 0.9701) | üéØ Test:  62.19% (loss: 0.9885)\n",
      "üî• √âpoca 35/50 | üìà Train:  60.44% (loss: 0.9684) | üéØ Test:  61.88% (loss: 0.9864)\n",
      "üî• √âpoca 36/50 | üìà Train:  60.83% (loss: 0.9672) | üéØ Test:  62.19% (loss: 0.9861)\n",
      "üî• √âpoca 37/50 | üìà Train:  60.67% (loss: 0.9650) | üéØ Test:  61.88% (loss: 0.9844)\n",
      "üî• √âpoca 38/50 | üìà Train:  60.75% (loss: 0.9635) | üéØ Test:  61.56% (loss: 0.9833)\n",
      "üî• √âpoca 39/50 | üìà Train:  60.59% (loss: 0.9618) | üéØ Test:  61.88% (loss: 0.9818)\n",
      "üî• √âpoca 40/50 | üìà Train:  60.91% (loss: 0.9600) | üéØ Test:  61.25% (loss: 0.9814)\n",
      "üî• √âpoca 41/50 | üìà Train:  61.14% (loss: 0.9588) | üéØ Test:  62.50% (loss: 0.9796)\n",
      "üî• √âpoca 42/50 | üìà Train:  60.99% (loss: 0.9571) | üéØ Test:  62.50% (loss: 0.9784)\n",
      "üî• √âpoca 43/50 | üìà Train:  61.06% (loss: 0.9558) | üéØ Test:  62.50% (loss: 0.9775)\n",
      "üî• √âpoca 44/50 | üìà Train:  61.45% (loss: 0.9542) | üéØ Test:  62.50% (loss: 0.9768)\n",
      "üî• √âpoca 45/50 | üìà Train:  62.08% (loss: 0.9520) | üéØ Test:  61.56% (loss: 0.9778)\n",
      "üî• √âpoca 46/50 | üìà Train:  61.45% (loss: 0.9511) | üéØ Test:  61.88% (loss: 0.9768)\n",
      "üî• √âpoca 47/50 | üìà Train:  61.22% (loss: 0.9498) | üéØ Test:  62.50% (loss: 0.9749)\n",
      "üî• √âpoca 48/50 | üìà Train:  61.14% (loss: 0.9487) | üéØ Test:  62.50% (loss: 0.9738)\n",
      "üî• √âpoca 49/50 | üìà Train:  61.53% (loss: 0.9470) | üéØ Test:  62.50% (loss: 0.9736)\n",
      "üî• √âpoca 50/50 | üìà Train:  61.38% (loss: 0.9456) | üéØ Test:  62.81% (loss: 0.9714)\n",
      "üî• √âpoca 41/50 | üìà Train:  61.14% (loss: 0.9588) | üéØ Test:  62.50% (loss: 0.9796)\n",
      "üî• √âpoca 42/50 | üìà Train:  60.99% (loss: 0.9571) | üéØ Test:  62.50% (loss: 0.9784)\n",
      "üî• √âpoca 43/50 | üìà Train:  61.06% (loss: 0.9558) | üéØ Test:  62.50% (loss: 0.9775)\n",
      "üî• √âpoca 44/50 | üìà Train:  61.45% (loss: 0.9542) | üéØ Test:  62.50% (loss: 0.9768)\n",
      "üî• √âpoca 45/50 | üìà Train:  62.08% (loss: 0.9520) | üéØ Test:  61.56% (loss: 0.9778)\n",
      "üî• √âpoca 46/50 | üìà Train:  61.45% (loss: 0.9511) | üéØ Test:  61.88% (loss: 0.9768)\n",
      "üî• √âpoca 47/50 | üìà Train:  61.22% (loss: 0.9498) | üéØ Test:  62.50% (loss: 0.9749)\n",
      "üî• √âpoca 48/50 | üìà Train:  61.14% (loss: 0.9487) | üéØ Test:  62.50% (loss: 0.9738)\n",
      "üî• √âpoca 49/50 | üìà Train:  61.53% (loss: 0.9470) | üéØ Test:  62.50% (loss: 0.9736)\n",
      "üî• √âpoca 50/50 | üìà Train:  61.38% (loss: 0.9456) | üéØ Test:  62.81% (loss: 0.9714)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"üî• √âpoca {epoch+1:2d}/50 | \"\n",
    "      f\"üìà Train: {train_acc:6.2f}% (loss: {train_loss:.4f}) | \"\n",
    "      f\"üéØ Test: {test_acc:6.2f}% (loss: {test_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10b99103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODELO BINARIO GOOD/BAD ===\n",
      "Distribuci√≥n binaria: [744 855]\n",
      "Bad wines (3-5): 744\n",
      "Good wines (6-8): 855\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENTO: Clasificaci√≥n binaria Good/Bad\n",
    "print(\"=== MODELO BINARIO GOOD/BAD ===\")\n",
    "\n",
    "# Convertir a binario: 3,4,5 ‚Üí 0 (Bad), 6,7,8 ‚Üí 1 (Good)\n",
    "y_binary = (y >= 6).astype(int)  # True/False ‚Üí 1/0\n",
    "print(f\"Distribuci√≥n binaria: {np.bincount(y_binary)}\")\n",
    "print(f\"Bad wines (3-5): {np.sum(y_binary == 0)}\")\n",
    "print(f\"Good wines (6-8): {np.sum(y_binary == 1)}\")\n",
    "\n",
    "# Split train/test para binario\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    X_scaled, y_binary, test_size=0.2, random_state=43, stratify=y_binary\n",
    ")\n",
    "\n",
    "# Convertir a tensores\n",
    "X_train_bin_tensor = torch.FloatTensor(X_train_bin)\n",
    "X_test_bin_tensor = torch.FloatTensor(X_test_bin)\n",
    "y_train_bin_tensor = torch.LongTensor(y_train_bin)  # Ya est√°n en 0-1\n",
    "y_test_bin_tensor = torch.LongTensor(y_test_bin)\n",
    "\n",
    "# Crear datasets binarios\n",
    "train_dataset_bin = data.TensorDataset(X_train_bin_tensor, y_train_bin_tensor)\n",
    "test_dataset_bin = data.TensorDataset(X_test_bin_tensor, y_test_bin_tensor)\n",
    "\n",
    "# DataLoaders binarios\n",
    "train_loader_bin = data.DataLoader(train_dataset_bin, batch_size=128, shuffle=True)\n",
    "test_loader_bin = data.DataLoader(test_dataset_bin, batch_size=128, shuffle=False)\n",
    "\n",
    "# Modelo binario (solo 2 clases de salida)\n",
    "model_binary = nn.Sequential(\n",
    "    nn.Linear(n_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 2)  # Solo 2 clases: Bad/Good\n",
    ")\n",
    "\n",
    "model_binary = model_binary.to(device)\n",
    "\n",
    "criterion_bin = nn.CrossEntropyLoss()\n",
    "optimizer_bin = optim.SGD(model_binary.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0db852b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Entrenando modelo binario Good/Bad...\n",
      "üç∑ √âpoca  1/50 | üìà Train:  63.49% (loss: 0.6790) | üéØ Test:  67.81% (loss: 0.6701)\n",
      "üç∑ √âpoca  2/50 | üìà Train:  68.65% (loss: 0.6662) | üéØ Test:  69.38% (loss: 0.6594)\n",
      "üç∑ √âpoca  3/50 | üìà Train:  69.82% (loss: 0.6550) | üéØ Test:  69.06% (loss: 0.6498)\n",
      "üç∑ √âpoca  4/50 | üìà Train:  70.60% (loss: 0.6447) | üéØ Test:  69.69% (loss: 0.6409)\n",
      "üç∑ √âpoca  5/50 | üìà Train:  71.62% (loss: 0.6351) | üéØ Test:  70.94% (loss: 0.6324)\n",
      "üç∑ √âpoca  6/50 | üìà Train:  71.85% (loss: 0.6261) | üéØ Test:  71.25% (loss: 0.6245)\n",
      "üç∑ √âpoca  7/50 | üìà Train:  72.48% (loss: 0.6176) | üéØ Test:  71.25% (loss: 0.6170)\n",
      "üç∑ √âpoca  8/50 | üìà Train:  72.71% (loss: 0.6096) | üéØ Test:  71.56% (loss: 0.6099)\n",
      "üç∑ √âpoca  9/50 | üìà Train:  72.79% (loss: 0.6018) | üéØ Test:  71.56% (loss: 0.6032)\n",
      "üç∑ √âpoca 10/50 | üìà Train:  73.18% (loss: 0.5947) | üéØ Test:  71.25% (loss: 0.5969)\n",
      "üç∑ √âpoca 11/50 | üìà Train:  74.35% (loss: 0.5878) | üéØ Test:  71.25% (loss: 0.5911)\n",
      "üç∑ √âpoca 12/50 | üìà Train:  74.75% (loss: 0.5814) | üéØ Test:  71.88% (loss: 0.5857)\n",
      "üç∑ √âpoca 13/50 | üìà Train:  74.67% (loss: 0.5755) | üéØ Test:  70.94% (loss: 0.5807)\n",
      "üç∑ √âpoca 14/50 | üìà Train:  74.67% (loss: 0.5698) | üéØ Test:  70.94% (loss: 0.5762)\n",
      "üç∑ √âpoca 15/50 | üìà Train:  74.90% (loss: 0.5646) | üéØ Test:  71.56% (loss: 0.5721)\n",
      "üç∑ √âpoca 16/50 | üìà Train:  74.75% (loss: 0.5599) | üéØ Test:  71.56% (loss: 0.5683)\n",
      "üç∑ √âpoca 17/50 | üìà Train:  74.59% (loss: 0.5555) | üéØ Test:  71.88% (loss: 0.5648)\n",
      "üç∑ √âpoca 18/50 | üìà Train:  74.67% (loss: 0.5515) | üéØ Test:  71.88% (loss: 0.5617)\n",
      "üç∑ √âpoca 19/50 | üìà Train:  74.82% (loss: 0.5477) | üéØ Test:  71.25% (loss: 0.5589)\n",
      "üç∑ √âpoca 20/50 | üìà Train:  74.59% (loss: 0.5442) | üéØ Test:  71.56% (loss: 0.5564)\n",
      "üç∑ √âpoca 21/50 | üìà Train:  74.82% (loss: 0.5411) | üéØ Test:  71.88% (loss: 0.5543)\n",
      "üç∑ √âpoca 22/50 | üìà Train:  74.51% (loss: 0.5382) | üéØ Test:  71.88% (loss: 0.5522)\n",
      "üç∑ √âpoca 23/50 | üìà Train:  74.67% (loss: 0.5356) | üéØ Test:  72.19% (loss: 0.5506)\n",
      "üç∑ √âpoca 24/50 | üìà Train:  74.90% (loss: 0.5333) | üéØ Test:  72.19% (loss: 0.5491)\n",
      "üç∑ √âpoca 25/50 | üìà Train:  74.67% (loss: 0.5310) | üéØ Test:  72.19% (loss: 0.5478)\n",
      "üç∑ √âpoca 26/50 | üìà Train:  74.82% (loss: 0.5288) | üéØ Test:  72.50% (loss: 0.5466)\n",
      "üç∑ √âpoca 27/50 | üìà Train:  74.90% (loss: 0.5269) | üéØ Test:  72.19% (loss: 0.5456)\n",
      "üç∑ √âpoca 28/50 | üìà Train:  75.06% (loss: 0.5251) | üéØ Test:  72.19% (loss: 0.5447)\n",
      "üç∑ √âpoca 14/50 | üìà Train:  74.67% (loss: 0.5698) | üéØ Test:  70.94% (loss: 0.5762)\n",
      "üç∑ √âpoca 15/50 | üìà Train:  74.90% (loss: 0.5646) | üéØ Test:  71.56% (loss: 0.5721)\n",
      "üç∑ √âpoca 16/50 | üìà Train:  74.75% (loss: 0.5599) | üéØ Test:  71.56% (loss: 0.5683)\n",
      "üç∑ √âpoca 17/50 | üìà Train:  74.59% (loss: 0.5555) | üéØ Test:  71.88% (loss: 0.5648)\n",
      "üç∑ √âpoca 18/50 | üìà Train:  74.67% (loss: 0.5515) | üéØ Test:  71.88% (loss: 0.5617)\n",
      "üç∑ √âpoca 19/50 | üìà Train:  74.82% (loss: 0.5477) | üéØ Test:  71.25% (loss: 0.5589)\n",
      "üç∑ √âpoca 20/50 | üìà Train:  74.59% (loss: 0.5442) | üéØ Test:  71.56% (loss: 0.5564)\n",
      "üç∑ √âpoca 21/50 | üìà Train:  74.82% (loss: 0.5411) | üéØ Test:  71.88% (loss: 0.5543)\n",
      "üç∑ √âpoca 22/50 | üìà Train:  74.51% (loss: 0.5382) | üéØ Test:  71.88% (loss: 0.5522)\n",
      "üç∑ √âpoca 23/50 | üìà Train:  74.67% (loss: 0.5356) | üéØ Test:  72.19% (loss: 0.5506)\n",
      "üç∑ √âpoca 24/50 | üìà Train:  74.90% (loss: 0.5333) | üéØ Test:  72.19% (loss: 0.5491)\n",
      "üç∑ √âpoca 25/50 | üìà Train:  74.67% (loss: 0.5310) | üéØ Test:  72.19% (loss: 0.5478)\n",
      "üç∑ √âpoca 26/50 | üìà Train:  74.82% (loss: 0.5288) | üéØ Test:  72.50% (loss: 0.5466)\n",
      "üç∑ √âpoca 27/50 | üìà Train:  74.90% (loss: 0.5269) | üéØ Test:  72.19% (loss: 0.5456)\n",
      "üç∑ √âpoca 28/50 | üìà Train:  75.06% (loss: 0.5251) | üéØ Test:  72.19% (loss: 0.5447)\n",
      "üç∑ √âpoca 29/50 | üìà Train:  74.90% (loss: 0.5237) | üéØ Test:  72.19% (loss: 0.5438)\n",
      "üç∑ √âpoca 30/50 | üìà Train:  75.06% (loss: 0.5221) | üéØ Test:  72.19% (loss: 0.5431)\n",
      "üç∑ √âpoca 31/50 | üìà Train:  75.06% (loss: 0.5206) | üéØ Test:  72.19% (loss: 0.5425)\n",
      "üç∑ √âpoca 32/50 | üìà Train:  75.29% (loss: 0.5192) | üéØ Test:  72.19% (loss: 0.5420)\n",
      "üç∑ √âpoca 33/50 | üìà Train:  74.98% (loss: 0.5182) | üéØ Test:  72.19% (loss: 0.5415)\n",
      "üç∑ √âpoca 34/50 | üìà Train:  75.22% (loss: 0.5172) | üéØ Test:  72.19% (loss: 0.5411)\n",
      "üç∑ √âpoca 35/50 | üìà Train:  75.29% (loss: 0.5161) | üéØ Test:  72.19% (loss: 0.5408)\n",
      "üç∑ √âpoca 36/50 | üìà Train:  75.29% (loss: 0.5151) | üéØ Test:  72.19% (loss: 0.5403)\n",
      "üç∑ √âpoca 37/50 | üìà Train:  75.45% (loss: 0.5141) | üéØ Test:  72.50% (loss: 0.5400)\n",
      "üç∑ √âpoca 38/50 | üìà Train:  75.29% (loss: 0.5132) | üéØ Test:  72.50% (loss: 0.5398)\n",
      "üç∑ √âpoca 39/50 | üìà Train:  75.06% (loss: 0.5124) | üéØ Test:  72.81% (loss: 0.5397)\n",
      "üç∑ √âpoca 40/50 | üìà Train:  75.29% (loss: 0.5116) | üéØ Test:  72.50% (loss: 0.5395)\n",
      "üç∑ √âpoca 41/50 | üìà Train:  75.29% (loss: 0.5108) | üéØ Test:  72.50% (loss: 0.5393)\n",
      "üç∑ √âpoca 42/50 | üìà Train:  75.29% (loss: 0.5101) | üéØ Test:  72.50% (loss: 0.5391)\n",
      "üç∑ √âpoca 29/50 | üìà Train:  74.90% (loss: 0.5237) | üéØ Test:  72.19% (loss: 0.5438)\n",
      "üç∑ √âpoca 30/50 | üìà Train:  75.06% (loss: 0.5221) | üéØ Test:  72.19% (loss: 0.5431)\n",
      "üç∑ √âpoca 31/50 | üìà Train:  75.06% (loss: 0.5206) | üéØ Test:  72.19% (loss: 0.5425)\n",
      "üç∑ √âpoca 32/50 | üìà Train:  75.29% (loss: 0.5192) | üéØ Test:  72.19% (loss: 0.5420)\n",
      "üç∑ √âpoca 33/50 | üìà Train:  74.98% (loss: 0.5182) | üéØ Test:  72.19% (loss: 0.5415)\n",
      "üç∑ √âpoca 34/50 | üìà Train:  75.22% (loss: 0.5172) | üéØ Test:  72.19% (loss: 0.5411)\n",
      "üç∑ √âpoca 35/50 | üìà Train:  75.29% (loss: 0.5161) | üéØ Test:  72.19% (loss: 0.5408)\n",
      "üç∑ √âpoca 36/50 | üìà Train:  75.29% (loss: 0.5151) | üéØ Test:  72.19% (loss: 0.5403)\n",
      "üç∑ √âpoca 37/50 | üìà Train:  75.45% (loss: 0.5141) | üéØ Test:  72.50% (loss: 0.5400)\n",
      "üç∑ √âpoca 38/50 | üìà Train:  75.29% (loss: 0.5132) | üéØ Test:  72.50% (loss: 0.5398)\n",
      "üç∑ √âpoca 39/50 | üìà Train:  75.06% (loss: 0.5124) | üéØ Test:  72.81% (loss: 0.5397)\n",
      "üç∑ √âpoca 40/50 | üìà Train:  75.29% (loss: 0.5116) | üéØ Test:  72.50% (loss: 0.5395)\n",
      "üç∑ √âpoca 41/50 | üìà Train:  75.29% (loss: 0.5108) | üéØ Test:  72.50% (loss: 0.5393)\n",
      "üç∑ √âpoca 42/50 | üìà Train:  75.29% (loss: 0.5101) | üéØ Test:  72.50% (loss: 0.5391)\n",
      "üç∑ √âpoca 43/50 | üìà Train:  75.29% (loss: 0.5092) | üéØ Test:  72.50% (loss: 0.5389)\n",
      "üç∑ √âpoca 44/50 | üìà Train:  75.37% (loss: 0.5086) | üéØ Test:  72.50% (loss: 0.5386)\n",
      "üç∑ √âpoca 45/50 | üìà Train:  75.45% (loss: 0.5079) | üéØ Test:  72.50% (loss: 0.5384)\n",
      "üç∑ √âpoca 46/50 | üìà Train:  75.84% (loss: 0.5075) | üéØ Test:  72.50% (loss: 0.5382)\n",
      "üç∑ √âpoca 47/50 | üìà Train:  75.76% (loss: 0.5067) | üéØ Test:  72.50% (loss: 0.5380)\n",
      "üç∑ √âpoca 48/50 | üìà Train:  75.92% (loss: 0.5060) | üéØ Test:  72.50% (loss: 0.5378)\n",
      "üç∑ √âpoca 49/50 | üìà Train:  76.00% (loss: 0.5055) | üéØ Test:  72.50% (loss: 0.5379)\n",
      "üç∑ √âpoca 50/50 | üìà Train:  76.00% (loss: 0.5050) | üéØ Test:  71.88% (loss: 0.5379)\n",
      "üç∑ √âpoca 43/50 | üìà Train:  75.29% (loss: 0.5092) | üéØ Test:  72.50% (loss: 0.5389)\n",
      "üç∑ √âpoca 44/50 | üìà Train:  75.37% (loss: 0.5086) | üéØ Test:  72.50% (loss: 0.5386)\n",
      "üç∑ √âpoca 45/50 | üìà Train:  75.45% (loss: 0.5079) | üéØ Test:  72.50% (loss: 0.5384)\n",
      "üç∑ √âpoca 46/50 | üìà Train:  75.84% (loss: 0.5075) | üéØ Test:  72.50% (loss: 0.5382)\n",
      "üç∑ √âpoca 47/50 | üìà Train:  75.76% (loss: 0.5067) | üéØ Test:  72.50% (loss: 0.5380)\n",
      "üç∑ √âpoca 48/50 | üìà Train:  75.92% (loss: 0.5060) | üéØ Test:  72.50% (loss: 0.5378)\n",
      "üç∑ √âpoca 49/50 | üìà Train:  76.00% (loss: 0.5055) | üéØ Test:  72.50% (loss: 0.5379)\n",
      "üç∑ √âpoca 50/50 | üìà Train:  76.00% (loss: 0.5050) | üéØ Test:  71.88% (loss: 0.5379)\n"
     ]
    }
   ],
   "source": [
    "# ENTRENAR MODELO BINARIO\n",
    "print(\"üöÄ Entrenando modelo binario Good/Bad...\")\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss, train_acc = train_epoch(model_binary, train_loader_bin, criterion_bin, optimizer_bin, device)\n",
    "    test_loss, test_acc = evaluate(model_binary, test_loader_bin, criterion_bin, device)\n",
    "\n",
    "    print(f\"üç∑ √âpoca {epoch+1:2d}/50 | \"\n",
    "      f\"üìà Train: {train_acc:6.2f}% (loss: {train_loss:.4f}) | \"\n",
    "      f\"üéØ Test: {test_acc:6.2f}% (loss: {test_loss:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
