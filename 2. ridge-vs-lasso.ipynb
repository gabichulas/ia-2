{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":741735,"sourceType":"datasetVersion","datasetId":383055}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Car Price Prediction: Ridge & Lasso","metadata":{}},{"cell_type":"markdown","source":"En este ejercicio tenemos como objetivo predecir el precio de un auto en el mercado estadounidense, entendiendo qué variables son más o menos determinantes a la hora de hacerlo.\n\nPrimero, cargamos los datos y visualizamos las primeras cinco filas:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(\"/kaggle/input/car-price-prediction/CarPrice_Assignment.csv\")\n\nprint(\"First 5 records:\", df.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-14T01:04:53.960423Z","iopub.execute_input":"2025-08-14T01:04:53.960802Z","iopub.status.idle":"2025-08-14T01:04:54.021723Z","shell.execute_reply.started":"2025-08-14T01:04:53.960773Z","shell.execute_reply":"2025-08-14T01:04:54.020833Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Primeramente identificamos unas cuantas variables categóricas que tendremos que one-hot-encodear. \n\nSeguimos analizando los datos:","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T01:08:52.189081Z","iopub.execute_input":"2025-08-14T01:08:52.189835Z","iopub.status.idle":"2025-08-14T01:08:52.245308Z","shell.execute_reply.started":"2025-08-14T01:08:52.189803Z","shell.execute_reply":"2025-08-14T01:08:52.244554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T01:28:42.686835Z","iopub.execute_input":"2025-08-14T01:28:42.687208Z","iopub.status.idle":"2025-08-14T01:28:42.710264Z","shell.execute_reply.started":"2025-08-14T01:28:42.687181Z","shell.execute_reply":"2025-08-14T01:28:42.709109Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Lo primero que identificamos es que no hay valores nulos, lo cual, en principio, es bueno.\n\nVamos a graficar una matriz de correlación solo usando las variables numéricas:","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf_numerical = df.drop([\"car_ID\", \"CarName\", \"fueltype\", \"aspiration\", \"doornumber\", \"carbody\", \"drivewheel\", \"enginelocation\", \"enginetype\", \"cylindernumber\", \"fuelsystem\"], axis=1)\n\ncorr = df_numerical.corr()\nplt.figure(figsize=(6, 4))\nsns.heatmap(corr, cmap='coolwarm', center=0)\nplt.title(\"Matriz de correlación\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T01:37:23.641108Z","iopub.execute_input":"2025-08-14T01:37:23.641479Z","iopub.status.idle":"2025-08-14T01:37:23.988930Z","shell.execute_reply.started":"2025-08-14T01:37:23.641454Z","shell.execute_reply":"2025-08-14T01:37:23.988022Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Podemos ver que la feature más correlacionada con `price` es `enginesize`, seguida por `curbweight` y `horsepower`. \n\nVamos a probar unos cuantos modelos para ver cual tomamos como baseline:\n\n- Regresión lineal usando `enginesize` como *X*.\n- Regresión múltiple usando `enginesize`, `curbweight` y `horsepower`.\n- Regresión múltiple usando *todas* las variables luego de one-hot-encodear las categóricas.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\n\n# Primer modelo\n\ny = df[\"price\"]\n\nX_1 = df[[\"enginesize\"]]\nX_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y, test_size=0.25, random_state=42)\n\nmodel_1 = LinearRegression()\nmodel_1.fit(X_train_1, y_train_1)\n\n# Segundo modelo\n\nX_2 = df[[\"enginesize\", \"curbweight\", \"horsepower\"]]\n\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y, test_size=0.25, random_state=42)\n\nmodel_2 = LinearRegression()\nmodel_2.fit(X_train_2, y_train_2)\n\n# Tercer modelo\n\nX_3 = df.drop(\"price\", axis=1)\n\ncategorical_cols = X_3.select_dtypes(include=['object']).columns\nnumeric_cols = X_3.select_dtypes(include=['int64', 'float64']).columns\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)\n    ], remainder='passthrough')\n\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', LinearRegression())\n])\n\nX_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y, test_size=0.25, random_state=42)\n\npipeline.fit(X_train_3, y_train_3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T02:53:34.309752Z","iopub.execute_input":"2025-08-14T02:53:34.310372Z","iopub.status.idle":"2025-08-14T02:53:34.374452Z","shell.execute_reply.started":"2025-08-14T02:53:34.310344Z","shell.execute_reply":"2025-08-14T02:53:34.372547Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Luego, evaluamos y comparamos estos tres modelos:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Diccionarios para almacenar métricas\nmetrics = {'Modelo': [], 'R2_train': [], 'R2_test': [], 'MSE_train': [], 'MSE_test': []}\n\n# --- Modelo 1 ---\ny_pred_train_1 = model_1.predict(X_train_1)\ny_pred_test_1 = model_1.predict(X_test_1)\n\nmetrics['Modelo'].append('Model 1 (enginesize)')\nmetrics['R2_train'].append(r2_score(y_train_1, y_pred_train_1))\nmetrics['R2_test'].append(r2_score(y_test_1, y_pred_test_1))\nmetrics['MSE_train'].append(mean_squared_error(y_train_1, y_pred_train_1))\nmetrics['MSE_test'].append(mean_squared_error(y_test_1, y_pred_test_1))\n\n# --- Modelo 2 ---\ny_pred_train_2 = model_2.predict(X_train_2)\ny_pred_test_2 = model_2.predict(X_test_2)\n\nmetrics['Modelo'].append('Model 2 (3 num)')\nmetrics['R2_train'].append(r2_score(y_train_2, y_pred_train_2))\nmetrics['R2_test'].append(r2_score(y_test_2, y_pred_test_2))\nmetrics['MSE_train'].append(mean_squared_error(y_train_2, y_pred_train_2))\nmetrics['MSE_test'].append(mean_squared_error(y_test_2, y_pred_test_2))\n\n# --- Modelo 3 (pipeline con todas las variables) ---\ny_pred_train_3 = pipeline.predict(X_train_3)\ny_pred_test_3 = pipeline.predict(X_test_3)\n\nmetrics['Modelo'].append('Model 3 (todas)')\nmetrics['R2_train'].append(r2_score(y_train_3, y_pred_train_3))\nmetrics['R2_test'].append(r2_score(y_test_3, y_pred_test_3))\nmetrics['MSE_train'].append(mean_squared_error(y_train_3, y_pred_train_3))\nmetrics['MSE_test'].append(mean_squared_error(y_test_3, y_pred_test_3))\n\nmetrics_df = pd.DataFrame(metrics)\nprint(metrics_df)\n\n# --- Graficos comparativos ---\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# R2 plot\naxes[0].bar(metrics_df['Modelo'], metrics_df['R2_train'], alpha=0.7, label='Train')\naxes[0].bar(metrics_df['Modelo'], metrics_df['R2_test'], alpha=0.7, label='Test')\naxes[0].set_ylim(0,1)\naxes[0].set_title('R² Train vs Test')\naxes[0].legend()\naxes[0].set_ylabel('R²')\n\n# MSE plot\naxes[1].bar(metrics_df['Modelo'], metrics_df['MSE_train'], alpha=0.7, label='Train')\naxes[1].bar(metrics_df['Modelo'], metrics_df['MSE_test'], alpha=0.7, label='Test')\naxes[1].set_title('MSE Train vs Test')\naxes[1].legend()\naxes[1].set_ylabel('MSE')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T02:53:42.700578Z","iopub.execute_input":"2025-08-14T02:53:42.700898Z","iopub.status.idle":"2025-08-14T02:53:43.081918Z","shell.execute_reply.started":"2025-08-14T02:53:42.700875Z","shell.execute_reply":"2025-08-14T02:53:43.081019Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"- El modelo 1 es bueno, con un R2 bastante mejor en test que en train (puede ser casualidad debido a que el dataset no es muy grande) y MSE muy similares entre train y test.\n- El segundo modelo es mejor al tener más información con la que trabajar, teniendo incluso menor MSE que el modelo 2.\n- El último modelo, que considera **todas** las features, parece ser muy malo. Un R2 tan cercano a 1 en el train set y tan malo en el test set nos dice que hay un *overfitting enorme*. Esto tambien se refleja en el MSE, siendo abismalmente más grande que sus predecesores. Una muy probable causa de esto es la gran cantidad de variables categóricas one-hot-encodeadas, es decir, **el modelo es demasiado complejo para los datos disponibles**. Afortunadamente, podemos resolver este problema con **Ridge** y **Lasso**.\n\nEl modelo 2 es el mejor y el que tomaremos como baseline.","metadata":{}},{"cell_type":"markdown","source":"A continuación, entrenamos Ridge y Lasso:","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge, Lasso\n\nX = df.drop(\"price\", axis=1)\ny = df[\"price\"]\n\ncategorical_cols = X.select_dtypes(include=['object']).columns\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n\n# Escalado de variables numéricas\nscaler = StandardScaler()\nX_num_scaled = scaler.fit_transform(X[numeric_cols])\n\n# One-hot-encoding de categóricas\nencoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\nX_cat_encoded = encoder.fit_transform(X[categorical_cols])\n\nimport numpy as np\nX_full = np.hstack([X_num_scaled, X_cat_encoded])\n\nmodels = {\n    \"Ridge (todas)\": Ridge(alpha=1.0),\n    \"Lasso (todas)\": Lasso(alpha=1.0)\n}\n\nresults = {'Modelo': [], 'R2_train': [], 'R2_test': [], 'MSE_train': [], 'MSE_test': []}\n\nfor name, model in models.items():\n    X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n    model.fit(X_train, y_train)\n    y_pred_train = model.predict(X_train)\n    y_pred_test = model.predict(X_test)\n    \n    results['Modelo'].append(name)\n    results['R2_train'].append(r2_score(y_train, y_pred_train))\n    results['R2_test'].append(r2_score(y_test, y_pred_test))\n    results['MSE_train'].append(mean_squared_error(y_train, y_pred_train))\n    results['MSE_test'].append(mean_squared_error(y_test, y_pred_test))\n\nresults['Modelo'].append(\"Model 2 (3 num)\")\nresults['R2_train'].append(r2_score(y_train_2, y_pred_train_2))\nresults['R2_test'].append(r2_score(y_test_2, y_pred_test_2))\nresults['MSE_train'].append(mean_squared_error(y_train_2, y_pred_train_2))\nresults['MSE_test'].append(mean_squared_error(y_test_2, y_pred_test_2))\n\nresults_df = pd.DataFrame(results)\nprint(results_df)\n\nfig, axes = plt.subplots(1,2, figsize=(12,5))\n\n# R2 plot\naxes[0].bar(results_df['Modelo'], results_df['R2_train'], alpha=0.7, label='Train')\naxes[0].bar(results_df['Modelo'], results_df['R2_test'], alpha=0.7, label='Test')\naxes[0].set_ylim(-0.5,1)\naxes[0].set_title('R² Train vs Test')\naxes[0].legend()\naxes[0].set_ylabel('R²')\naxes[0].tick_params(axis='x', rotation=30)\n\n# MSE plot\naxes[1].bar(results_df['Modelo'], results_df['MSE_train'], alpha=0.7, label='Train')\naxes[1].bar(results_df['Modelo'], results_df['MSE_test'], alpha=0.7, label='Test')\naxes[1].set_title('MSE Train vs Test')\naxes[1].legend()\naxes[1].set_ylabel('MSE')\naxes[1].tick_params(axis='x', rotation=30)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T03:11:14.393700Z","iopub.execute_input":"2025-08-14T03:11:14.394398Z","iopub.status.idle":"2025-08-14T03:11:14.847449Z","shell.execute_reply.started":"2025-08-14T03:11:14.394371Z","shell.execute_reply":"2025-08-14T03:11:14.846508Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Podemos ver que Ridge mejoró al modelo 2, con un R2 más alto y un MSE mucho menor. Al contrario, Lasso *overfittea*.\n\nPero estamos usando lambdas (en este caso alphas) para nada optimizados, por lo que vamos a buscar valores más óptimos para este hiperparámetro. Podríamos usar cross validation, pero vamos a hacer un barrido de forma que veamos el cambio gráficamente:","metadata":{}},{"cell_type":"code","source":"alphas = np.logspace(-3, 2, 50)  # valores desde 0.001 hasta 100\nr2_train_list = []\nr2_test_list = []\n\nr2_train_ridge, r2_test_ridge = [], []\nr2_train_lasso, r2_test_lasso = [], []\n\nfor a in alphas:\n    # Ridge\n    ridge = Ridge(alpha=a)\n    ridge.fit(X_train, y_train)\n    r2_train_ridge.append(r2_score(y_train, ridge.predict(X_train)))\n    r2_test_ridge.append(r2_score(y_test, ridge.predict(X_test)))\n    \n    # Lasso\n    lasso = Lasso(alpha=a, max_iter=10000)\n    lasso.fit(X_train, y_train)\n    r2_train_lasso.append(r2_score(y_train, lasso.predict(X_train)))\n    r2_test_lasso.append(r2_score(y_test, lasso.predict(X_test)))\n\n\nbest_alpha_ridge = alphas[np.argmax(r2_test_ridge)]\nbest_r2_ridge = max(r2_test_ridge)\n\nbest_alpha_lasso = alphas[np.argmax(r2_test_lasso)]\nbest_r2_lasso = max(r2_test_lasso)\n\nprint(f\"Ridge: mejor alpha = {best_alpha_ridge:.5f}, R² test = {best_r2_ridge:.5f}\")\nprint(f\"Lasso: mejor alpha = {best_alpha_lasso:.5f}, R² test = {best_r2_lasso:.5f}\")\n\n# --- Graficar ---\nplt.figure(figsize=(10,6))\nplt.semilogx(alphas, r2_test_ridge, 'b--o', label='R² Test Ridge')\nplt.semilogx(alphas, r2_test_lasso, 'r--o', label='R² Test Lasso')\n\n# Marcar los α óptimos\nplt.scatter(best_alpha_ridge, best_r2_ridge, color='blue', s=100, marker='x', label=f'Ridge α óptimo')\nplt.scatter(best_alpha_lasso, best_r2_lasso, color='red', s=100, marker='x', label=f'Lasso α óptimo')\n\nplt.xlabel('Alpha (log scale)')\nplt.ylabel('R²')\nplt.title('Barrido de alpha: Ridge vs Lasso')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T03:41:06.482140Z","iopub.execute_input":"2025-08-14T03:41:06.482523Z","iopub.status.idle":"2025-08-14T03:41:13.625535Z","shell.execute_reply.started":"2025-08-14T03:41:06.482498Z","shell.execute_reply":"2025-08-14T03:41:13.624207Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Habiendo hecho este análisis, volvemos a graficar:","metadata":{}},{"cell_type":"code","source":"models = {\n    \"Ridge (todas)\": Ridge(alpha=best_alpha_ridge),\n    \"Lasso (todas)\": Lasso(alpha=best_alpha_lasso)\n}\n\nresults = {'Modelo': [], 'R2_train': [], 'R2_test': [], 'MSE_train': [], 'MSE_test': []}\n\nfor name, model in models.items():\n    X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n    model.fit(X_train, y_train)\n    y_pred_train = model.predict(X_train)\n    y_pred_test = model.predict(X_test)\n    \n    results['Modelo'].append(name)\n    results['R2_train'].append(r2_score(y_train, y_pred_train))\n    results['R2_test'].append(r2_score(y_test, y_pred_test))\n    results['MSE_train'].append(mean_squared_error(y_train, y_pred_train))\n    results['MSE_test'].append(mean_squared_error(y_test, y_pred_test))\n\nresults['Modelo'].append(\"Model 2 (3 num)\")\nresults['R2_train'].append(r2_score(y_train_2, y_pred_train_2))\nresults['R2_test'].append(r2_score(y_test_2, y_pred_test_2))\nresults['MSE_train'].append(mean_squared_error(y_train_2, y_pred_train_2))\nresults['MSE_test'].append(mean_squared_error(y_test_2, y_pred_test_2))\n\nresults_df = pd.DataFrame(results)\nprint(results_df)\n\nfig, axes = plt.subplots(1,2, figsize=(12,5))\n\n# R2 plot\naxes[0].bar(results_df['Modelo'], results_df['R2_train'], alpha=0.7, label='Train')\naxes[0].bar(results_df['Modelo'], results_df['R2_test'], alpha=0.7, label='Test')\naxes[0].set_ylim(-0.5,1)\naxes[0].set_title('R² Train vs Test')\naxes[0].legend()\naxes[0].set_ylabel('R²')\naxes[0].tick_params(axis='x', rotation=30)\n\n# MSE plot\naxes[1].bar(results_df['Modelo'], results_df['MSE_train'], alpha=0.7, label='Train')\naxes[1].bar(results_df['Modelo'], results_df['MSE_test'], alpha=0.7, label='Test')\naxes[1].set_title('MSE Train vs Test')\naxes[1].legend()\naxes[1].set_ylabel('MSE')\naxes[1].tick_params(axis='x', rotation=30)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T03:19:57.400513Z","iopub.execute_input":"2025-08-14T03:19:57.401384Z","iopub.status.idle":"2025-08-14T03:19:57.815523Z","shell.execute_reply.started":"2025-08-14T03:19:57.401354Z","shell.execute_reply":"2025-08-14T03:19:57.814461Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ahora se ve mucho mejor! Lasso ya no overfittea, aunque Ridge sigue siendo ligeramente mejor, teniendo mejor R2 y menor MSE.\n\nAhora, vamos a ver las variables que priorizaron estos modelos:","metadata":{}},{"cell_type":"code","source":"top_n = 15\n\nX_num = X[numeric_cols].columns\nX_cat = encoder.get_feature_names_out(categorical_cols)\nall_features = np.concatenate([X_num, X_cat])\n\n# --- Coeficientes Ridge ---\nridge_coef = pd.Series(models[\"Ridge (todas)\"].coef_, index=all_features)\nridge_coef_sorted = ridge_coef.sort_values(key=abs, ascending=False)\nridge_top = ridge_coef_sorted.head(top_n)\n\n# --- Coeficientes Lasso ---\nlasso_coef = pd.Series(models[\"Lasso (todas)\"].coef_, index=all_features)\nlasso_coef_sorted = lasso_coef.sort_values(key=abs, ascending=False)\nlasso_top = lasso_coef_sorted.head(top_n)\n\nfig, axes = plt.subplots(1,2, figsize=(14,6))\n\n# Ridge\naxes[0].barh(ridge_top.index[::-1], ridge_top.values[::-1], color='skyblue')\naxes[0].set_title(\"Top 15 coeficientes Ridge\")\naxes[0].set_xlabel(\"Coeficiente\")\naxes[0].set_ylabel(\"Variable\")\n\n# Lasso\naxes[1].barh(lasso_top.index[::-1], lasso_top.values[::-1], color='salmon')\naxes[1].set_title(\"Top 15 coeficientes Lasso\")\naxes[1].set_xlabel(\"Coeficiente\")\naxes[1].set_ylabel(\"Variable\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T03:26:47.344597Z","iopub.execute_input":"2025-08-14T03:26:47.344908Z","iopub.status.idle":"2025-08-14T03:26:48.006461Z","shell.execute_reply.started":"2025-08-14T03:26:47.344888Z","shell.execute_reply":"2025-08-14T03:26:48.005594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusión\n\nRidge fue la mejor opción, aunque logramos mejorar mucho el rendimiento de Lasso modificando lambda. Ridge eligió priorizar ciertos nombres de autos que seguramente son más caros que el resto, lo cual es algo a mejorar (no le veo mucho sentido si lo que queremos es predecir el precio de un nuevo auto). Al contrario, Lasso priorizó especificaciones de los vehículos.\n\nAlgo destacable es que ambos encontraron que la localización del motor (específicamente en la parte trasera) y el tamaño de este (lo cual descubrimos con la matriz de correlación) expresado en pulgadas cúbicas son los factores más determinantes a la hora de predecir el precio de un vehículo.","metadata":{}}]}